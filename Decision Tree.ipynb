{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import src.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "MNIST(N=55000, dataset=\"train\", labels=(55000,), images=(55000, 784), PCA=False, KMeans=False)\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "MNIST(N=10000, dataset=\"test\", labels=(10000,), images=(10000, 784), PCA=False, KMeans=False)\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = src.mnist.get_mnist_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=100, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=100)\n",
    "pca.fit(train_set.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_images_pca = pca.transform(train_set.images)\n",
    "test_images_pca = pca.transform(test_set.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are all the various decision tree algorithms and how do they differ from each other? Which one is implemented in scikit-learn?\n",
    "ID3 (Iterative Dichotomiser 3) was developed in 1986 by Ross Quinlan. The algorithm creates a multiway tree, finding for each node (i.e. in a greedy manner) the categorical feature that will yield the largest information gain for categorical targets. Trees are grown to their maximum size and then a pruning step is usually applied to improve the ability of the tree to generalise to unseen data.\n",
    "C4.5 is the successor to ID3 and removed the restriction that features must be categorical by dynamically defining a discrete attribute (based on numerical variables) that partitions the continuous attribute value into a discrete set of intervals. C4.5 converts the trained trees (i.e. the output of the ID3 algorithm) into sets of if-then rules. These accuracy of each rule is then evaluated to determine the order in which they should be applied. Pruning is done by removing a rule’s precondition if the accuracy of the rule improves without it.\n",
    "C5.0 is Quinlan’s latest version release under a proprietary license. It uses less memory and builds smaller rulesets than C4.5 while being more accurate.\n",
    "CART (Classification and Regression Trees) is very similar to C4.5, but it differs in that it supports numerical target variables (regression) and does not compute rule sets. CART constructs binary trees using the feature and threshold that yield the largest information gain at each node.\n",
    "scikit-learn uses an optimised version of the CART algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(train_images_pca, train_set.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_predictions = []\n",
    "for i in range(0, test_images_pca.shape[0]):\n",
    "    label = test_set.labels[i]\n",
    "    prediction = clf.predict(test_images_pca[i].reshape(1, -1))\n",
    "    labels_predictions.append([label, prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_confusion_matrix(n_classes, label_predictions):\n",
    "    ret = np.zeros((n_classes, n_classes))\n",
    "    for label_prediction in label_predictions:\n",
    "        label = label_prediction[0]\n",
    "        prediction = label_prediction[1]\n",
    "        ret[label, prediction] += 1\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_error_ratio(label_predictions):\n",
    "    n_errors = 0\n",
    "    for label_prediction in label_predictions:\n",
    "        label = label_prediction[0]\n",
    "        prediction = label_prediction[1]\n",
    "        if label != prediction:\n",
    "            n_errors += 1\n",
    "    return float(n_errors) / float(len(label_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion_matrix = get_confusion_matrix(10, labels_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  868.     2.    15.    10.     9.    19.    31.     6.    16.     4.]\n",
      " [    0.  1097.     2.     4.     5.     4.     4.     5.    10.     4.]\n",
      " [   15.     5.   836.    35.    13.    22.    30.    22.    42.    12.]\n",
      " [   13.     8.    20.   812.     5.    62.     9.    13.    52.    16.]\n",
      " [    1.     6.    16.     4.   787.    11.    16.    31.    14.    96.]\n",
      " [   23.     5.     9.    68.    18.   672.    22.    12.    40.    23.]\n",
      " [   20.     3.    14.     3.    17.    22.   858.     6.    10.     5.]\n",
      " [    6.     9.    31.    21.    19.     4.     5.   870.     9.    54.]\n",
      " [   13.     8.    39.    40.    14.    39.    13.    15.   759.    34.]\n",
      " [   10.     3.    10.     8.    82.    31.     8.    48.    27.   782.]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True, threshold=10000)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_ratio = get_error_ratio(labels_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1659\n"
     ]
    }
   ],
   "source": [
    "print(error_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50)\n",
    "clf = clf.fit(train_images_pca, train_set.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_predictions = []\n",
    "for i in range(0, test_images_pca.shape[0]):\n",
    "    label = test_set.labels[i]\n",
    "    prediction = clf.predict(test_images_pca[i].reshape(1, -1))\n",
    "    labels_predictions.append([label, prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix = get_confusion_matrix(10, labels_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  962.     0.     3.     1.     1.     3.     6.     1.     3.     0.]\n",
      " [    0.  1118.     4.     2.     0.     1.     5.     1.     3.     1.]\n",
      " [   11.     0.   965.    13.     8.     2.     3.     8.    19.     3.]\n",
      " [    3.     0.     7.   953.     1.    12.     3.    10.    17.     4.]\n",
      " [    1.     2.     5.     2.   928.     3.     9.     2.     5.    25.]\n",
      " [    5.     1.     5.    25.     6.   827.    11.     1.     5.     6.]\n",
      " [    6.     3.     2.     2.     4.     7.   933.     0.     1.     0.]\n",
      " [    0.     7.    20.     2.     9.     1.     0.   963.     3.    23.]\n",
      " [    8.     0.    17.    24.     7.    18.     5.     7.   879.     9.]\n",
      " [    5.     5.     5.    13.    26.     6.     1.    12.     8.   928.]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True, threshold=10000)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_ratio = get_error_ratio(labels_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0544\n"
     ]
    }
   ],
   "source": [
    "print(error_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
