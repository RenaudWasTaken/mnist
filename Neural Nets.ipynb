{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural Networks using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import src.mnist\n",
    "import src.const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot=True)\n",
    "\n",
    "train_set, test_set = mnist.train, mnist.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_reduced = train_set.kmeans.transform(train_set.images)\n",
    "k_test = train_set.kmeans.transform(test_set.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch(images, labels, batch_size, i):\n",
    "    start = i\n",
    "    i += batch_size\n",
    "    N = images.shape[0]\n",
    "    \n",
    "    if i > N:\n",
    "        perm = np.arange(N)\n",
    "        np.random.suffle(perm)\n",
    "        \n",
    "        images = images[perm]\n",
    "        labels = labels[perm]\n",
    "        \n",
    "        start = 0\n",
    "        i = batch_size\n",
    "    \n",
    "    end = i\n",
    "\n",
    "    return images, labels, i, images[start:end], labels[start:end]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import tee\n",
    "\n",
    "def pairwise(iterable):\n",
    "    \"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\n",
    "    a, b = tee(iterable)\n",
    "    next(b, None)\n",
    "\n",
    "    return zip(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 30\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "n_hidden_1 = 1024\n",
    "n_hidden_2 = 512\n",
    "n_hidden_3 = 256\n",
    "n_hidden_4 = 128\n",
    "n_input = 784\n",
    "n_classes = 10\n",
    "\n",
    "def build_network(n_input, n_classes, hlayers, optimizer=None, has_exp_decay=False, activation=None):\n",
    "\n",
    "    if not optimizer:\n",
    "        optimizer = tf.train.GradientDescentOptimizer\n",
    "    \n",
    "    if not activation:\n",
    "        activation = tf.sigmoid\n",
    "    \n",
    "    layers = [n_input] + hlayers\n",
    "    \n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "\n",
    "        x = tf.placeholder(\"float\", [None, n_input])\n",
    "        y = tf.placeholder(\"float\", [None, n_classes])\n",
    "        \n",
    "        if has_exp_decay:\n",
    "            global_step = tf.Variable(0)\n",
    "\n",
    "        def multilayer_perceptron(x, weights, biases):\n",
    "            layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "            layer_1 = tf.sigmoid(layer_1)\n",
    "\n",
    "            out_layer = tf.matmul(layer_1, weights['out']) + biases['out']\n",
    "\n",
    "            return out_layer\n",
    "\n",
    "        Var = tf.Variable\n",
    "        Ran = tf.random_normal\n",
    "        \n",
    "        biases = {'b%s' % i: Var(Ran([l])) for i, l in enumerate(layers[1:])}\n",
    "        biases['out'] = Var(Ran([n_classes]))\n",
    "        \n",
    "        weights = {'h%s' % i: Var(Ran([l_i, l_ii])) for i, (l_i, l_ii) in enumerate(pairwise(layers))}\n",
    "        weights['out'] = Var(Ran([layers[-1], n_classes]))\n",
    "        \n",
    "        prev_layer = x\n",
    "        for i in range(len(layers) - 1):\n",
    "            w, b = weights['h%s' % i], biases['b%s' % i]\n",
    "\n",
    "            layer = tf.add(tf.matmul(prev_layer, w), b)\n",
    "            layer = activation(layer)\n",
    "            \n",
    "            prev_layer = layer\n",
    "        \n",
    "        pred = tf.matmul(prev_layer, weights['out']) + biases['out']\n",
    "        \n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "\n",
    "        # exp_lr = tf.train.exponential_decay(learning_rate, global_step, 1000, 0.90, staircase=True)\n",
    "        # optimizer = tf.train.AdamOptimizer(exp_lr).minimize(cost, global_step=global_step)\n",
    "        optimizer = optimizer(learning_rate).minimize(cost)\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Grapher(train_set, test_set, n_input, n_classes, hlayers, optimizer=None,\n",
    "                       has_exp_decay=False, activation=None):\n",
    "        \n",
    "    optimizer = optimizer if optimizer else tf.train.GradientDescentOptimizer\n",
    "    activation = activation if activation else tf.sigmoid\n",
    "\n",
    "    layers = [n_input] + hlayers\n",
    "\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "\n",
    "        x = tf.placeholder(\"float\", [None, n_input])\n",
    "        y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "        if has_exp_decay:\n",
    "            global_step = tf.Variable(0)\n",
    "\n",
    "        Var = tf.Variable\n",
    "        Ran = tf.random_normal\n",
    "\n",
    "        biases = {'b%s' % i: Var(Ran([l])) for i, l in enumerate(layers[1:])}\n",
    "        biases['out'] = Var(Ran([n_classes]))\n",
    "\n",
    "        weights = {'h%s' % i: Var(Ran([l_i, l_ii])) for i, (l_i, l_ii) in enumerate(pairwise(layers))}\n",
    "        weights['out'] = Var(Ran([layers[-1], n_classes]))\n",
    "\n",
    "        prev_layer = x\n",
    "        for i in range(len(layers) - 1):\n",
    "            w, b = weights['h%s' % i], biases['b%s' % i]\n",
    "\n",
    "            layer = tf.add(tf.matmul(prev_layer, w), b)\n",
    "            layer = activation(layer)\n",
    "\n",
    "            prev_layer = layer\n",
    "\n",
    "        pred = tf.matmul(prev_layer, weights['out']) + biases['out']\n",
    "\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "\n",
    "        if has_exp_decay:\n",
    "            exp_lr = tf.train.exponential_decay(learning_rate, global_step, 1000, 0.90, staircase=True)\n",
    "            optimizer = tf.train.AdamOptimizer(exp_lr).minimize(cost, global_step=global_step)\n",
    "        else:\n",
    "            optimizer = optimizer(learning_rate).minimize(cost)\n",
    "\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        tf.initialize_all_variables().run()\n",
    "\n",
    "        print(\"Initialized\")\n",
    "        prev, curr = -1, 0\n",
    "        epoch = 0\n",
    "\n",
    "        while abs(curr - prev) > 0.1:\n",
    "            prev = curr\n",
    "\n",
    "            avg_cost = 0.\n",
    "            total_batch = int(train_set.num_examples / batch_size)\n",
    "\n",
    "            for i in range(total_batch):\n",
    "                batch_x, batch_y = train_set.next_batch(batch_size)\n",
    "                _, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})\n",
    "                avg_cost += c / total_batch\n",
    "\n",
    "            if epoch % display_step == 0:\n",
    "                print(\"Epoch:\", '%04d' % (epoch + 1), \"cost =\", \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "            epoch += 1\n",
    "\n",
    "            curr = avg_cost\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print(\"Accuracy:\", accuracy.eval({x: test_set.images, y: test_set.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Epoch: 0001 cost = 12.568821004\n",
      "Epoch: 0002 cost = 9.240629437\n",
      "Epoch: 0003 cost = 7.747553156\n",
      "Epoch: 0004 cost = 6.765919820\n",
      "Epoch: 0005 cost = 6.136766780\n",
      "Epoch: 0006 cost = 5.666180403\n",
      "Epoch: 0007 cost = 5.288129089\n",
      "Epoch: 0008 cost = 4.940382444\n",
      "Epoch: 0009 cost = 4.629014284\n",
      "Epoch: 0010 cost = 4.362127741\n",
      "Epoch: 0011 cost = 4.107666473\n",
      "Epoch: 0012 cost = 3.935222556\n",
      "Epoch: 0013 cost = 3.751227068\n",
      "Epoch: 0014 cost = 3.585853815\n",
      "Epoch: 0015 cost = 3.407629982\n",
      "Epoch: 0016 cost = 3.270236436\n",
      "Epoch: 0017 cost = 3.175762827\n",
      "Optimization Finished!\n",
      "Accuracy: 0.4935\n"
     ]
    }
   ],
   "source": [
    "Grapher(train_set, test_set, n_input, n_classes, [256],\n",
    "        tf.train.GradientDescentOptimizer, activation=tf.sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Epoch: 0001 cost = 9.275056529\n",
      "Epoch: 0002 cost = 6.591123818\n",
      "Epoch: 0003 cost = 5.749068124\n",
      "Epoch: 0004 cost = 5.074636205\n",
      "Epoch: 0005 cost = 4.566350620\n",
      "Epoch: 0006 cost = 4.180550253\n",
      "Epoch: 0007 cost = 3.850842323\n",
      "Epoch: 0008 cost = 3.586441510\n",
      "Epoch: 0009 cost = 3.371263473\n",
      "Epoch: 0010 cost = 3.172172715\n",
      "Epoch: 0011 cost = 3.012585413\n",
      "Epoch: 0012 cost = 2.860472160\n",
      "Epoch: 0013 cost = 2.729380232\n",
      "Epoch: 0014 cost = 2.632905596\n",
      "Optimization Finished!\n",
      "Accuracy: 0.503\n"
     ]
    }
   ],
   "source": [
    "Grapher(train_set, test_set, n_input, n_classes, [256, 256],\n",
    "        tf.train.GradientDescentOptimizer, activation=tf.sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Epoch: 0001 cost = 168.461362749\n",
      "Epoch: 0002 cost = 62.744317270\n",
      "Epoch: 0003 cost = 46.698486593\n",
      "Epoch: 0004 cost = 38.821199485\n",
      "Epoch: 0005 cost = 31.482605140\n",
      "Epoch: 0006 cost = 27.599581663\n",
      "Epoch: 0007 cost = 24.711671715\n",
      "Epoch: 0008 cost = 22.122395800\n",
      "Epoch: 0009 cost = 19.410969272\n",
      "Epoch: 0010 cost = 18.034688600\n",
      "Epoch: 0011 cost = 17.145818053\n",
      "Epoch: 0012 cost = 15.500657835\n",
      "Epoch: 0013 cost = 14.673952134\n",
      "Epoch: 0014 cost = 13.642148634\n",
      "Epoch: 0015 cost = 12.670881062\n",
      "Epoch: 0016 cost = 12.061243624\n",
      "Epoch: 0017 cost = 11.047795625\n",
      "Epoch: 0018 cost = 10.755847830\n",
      "Epoch: 0019 cost = 10.132051462\n",
      "Epoch: 0020 cost = 9.620841554\n",
      "Epoch: 0021 cost = 9.224581518\n",
      "Epoch: 0022 cost = 8.680838946\n",
      "Epoch: 0023 cost = 8.205091965\n",
      "Epoch: 0024 cost = 7.929797125\n",
      "Epoch: 0025 cost = 7.614313779\n",
      "Epoch: 0026 cost = 7.127340345\n",
      "Epoch: 0027 cost = 7.005310774\n",
      "Epoch: 0028 cost = 6.469353232\n",
      "Epoch: 0029 cost = 6.502118008\n",
      "Optimization Finished!\n",
      "Accuracy: 0.9219\n"
     ]
    }
   ],
   "source": [
    "Grapher(train_set, test_set, n_input, n_classes, [256, 256],\n",
    "        tf.train.GradientDescentOptimizer, activation=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Epoch: 0001 cost = 16.688322176\n",
      "Epoch: 0002 cost = 13.074088488\n",
      "Epoch: 0003 cost = 11.104799135\n",
      "Epoch: 0004 cost = 9.601502661\n",
      "Epoch: 0005 cost = 8.725808338\n",
      "Epoch: 0006 cost = 7.837694082\n",
      "Epoch: 0007 cost = 7.195812986\n",
      "Epoch: 0008 cost = 6.740403003\n",
      "Epoch: 0009 cost = 6.345725234\n",
      "Epoch: 0010 cost = 5.871733464\n",
      "Epoch: 0011 cost = 5.639490885\n",
      "Epoch: 0012 cost = 5.356760943\n",
      "Epoch: 0013 cost = 5.112513972\n",
      "Epoch: 0014 cost = 4.945968019\n",
      "Epoch: 0015 cost = 4.706601268\n",
      "Epoch: 0016 cost = 4.586755428\n",
      "Epoch: 0017 cost = 4.396630606\n",
      "Epoch: 0018 cost = 4.282278256\n",
      "Epoch: 0019 cost = 4.177132766\n",
      "Epoch: 0020 cost = 3.975218591\n",
      "Epoch: 0021 cost = 3.947260102\n",
      "Optimization Finished!\n",
      "Accuracy: 0.6354\n"
     ]
    }
   ],
   "source": [
    "Grapher(train_set, test_set, n_input, n_classes, [256, 256],\n",
    "        tf.train.GradientDescentOptimizer, activation=tf.tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Epoch: 0001 cost = 158.636479350\n",
      "Epoch: 0002 cost = 63.175238659\n",
      "Epoch: 0003 cost = 47.295233217\n",
      "Epoch: 0004 cost = 37.196117105\n",
      "Epoch: 0005 cost = 32.251805290\n",
      "Epoch: 0006 cost = 27.030370163\n",
      "Epoch: 0007 cost = 24.711034253\n",
      "Epoch: 0008 cost = 21.700759888\n",
      "Epoch: 0009 cost = 19.693960668\n",
      "Epoch: 0010 cost = 18.666757154\n",
      "Epoch: 0011 cost = 16.656596048\n",
      "Epoch: 0012 cost = 15.403089993\n",
      "Epoch: 0013 cost = 13.998912788\n",
      "Epoch: 0014 cost = 13.604372936\n",
      "Epoch: 0015 cost = 12.309657693\n",
      "Epoch: 0016 cost = 11.897913117\n",
      "Epoch: 0017 cost = 10.774219702\n",
      "Epoch: 0018 cost = 10.526115965\n",
      "Epoch: 0019 cost = 9.957187676\n",
      "Epoch: 0020 cost = 9.478471657\n",
      "Epoch: 0021 cost = 8.584910696\n",
      "Epoch: 0022 cost = 8.495057244\n",
      "Optimization Finished!\n",
      "Accuracy: 0.9212\n"
     ]
    }
   ],
   "source": [
    "Grapher(train_set, test_set, n_input, n_classes, [256, 256],\n",
    "        tf.train.GradientDescentOptimizer, activation=tf.nn.elu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Epoch: 0001 cost = 145.214975239\n",
      "Epoch: 0002 cost = 55.051630793\n",
      "Epoch: 0003 cost = 41.692173535\n",
      "Epoch: 0004 cost = 33.820915558\n",
      "Epoch: 0005 cost = 28.709974655\n",
      "Epoch: 0006 cost = 25.175938875\n",
      "Epoch: 0007 cost = 22.333532874\n",
      "Epoch: 0008 cost = 20.577434903\n",
      "Epoch: 0009 cost = 18.387683962\n",
      "Epoch: 0010 cost = 16.573732892\n",
      "Epoch: 0011 cost = 15.729543466\n",
      "Epoch: 0012 cost = 14.421685715\n",
      "Epoch: 0013 cost = 13.539032680\n",
      "Epoch: 0014 cost = 12.734992062\n",
      "Epoch: 0015 cost = 12.245311676\n",
      "Epoch: 0016 cost = 11.123402960\n",
      "Epoch: 0017 cost = 10.700283347\n",
      "Epoch: 0018 cost = 10.152210467\n",
      "Epoch: 0019 cost = 9.525157732\n",
      "Epoch: 0020 cost = 9.266509566\n",
      "Epoch: 0021 cost = 8.789047323\n",
      "Epoch: 0022 cost = 8.076773992\n",
      "Epoch: 0023 cost = 8.139067929\n",
      "Optimization Finished!\n",
      "Accuracy: 0.9112\n"
     ]
    }
   ],
   "source": [
    "Grapher(train_set, test_set, n_input, n_classes, [256, 256],\n",
    "        tf.train.GradientDescentOptimizer, activation=tf.nn.softplus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Epoch: 0001 cost = 17.914353048\n",
      "Epoch: 0002 cost = 12.976675747\n",
      "Epoch: 0003 cost = 10.377192303\n",
      "Epoch: 0004 cost = 8.814106817\n",
      "Epoch: 0005 cost = 7.676544284\n",
      "Epoch: 0006 cost = 6.938102120\n",
      "Epoch: 0007 cost = 6.215243773\n",
      "Epoch: 0008 cost = 5.838264429\n",
      "Epoch: 0009 cost = 5.451482548\n",
      "Epoch: 0010 cost = 5.110269877\n",
      "Epoch: 0011 cost = 4.793616508\n",
      "Epoch: 0012 cost = 4.571912144\n",
      "Epoch: 0013 cost = 4.393346232\n",
      "Epoch: 0014 cost = 4.220301905\n",
      "Epoch: 0015 cost = 3.994542176\n",
      "Epoch: 0016 cost = 3.906197088\n",
      "Optimization Finished!\n",
      "Accuracy: 0.6216\n"
     ]
    }
   ],
   "source": [
    "Grapher(train_set, test_set, n_input, n_classes, [256, 256],\n",
    "        tf.train.GradientDescentOptimizer, activation=tf.nn.softsign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Epoch: 0001 cost = 42.262833058\n",
      "Epoch: 0002 cost = 22.901573221\n",
      "Epoch: 0003 cost = 17.642307158\n",
      "Epoch: 0004 cost = 14.601805008\n",
      "Epoch: 0005 cost = 12.459141713\n",
      "Epoch: 0006 cost = 11.299387116\n",
      "Epoch: 0007 cost = 10.221891618\n",
      "Epoch: 0008 cost = 9.471752096\n",
      "Epoch: 0009 cost = 8.696619465\n",
      "Epoch: 0010 cost = 8.249033723\n",
      "Epoch: 0011 cost = 7.781070447\n",
      "Epoch: 0012 cost = 7.426614202\n",
      "Epoch: 0013 cost = 6.991343694\n",
      "Epoch: 0014 cost = 6.692083751\n",
      "Epoch: 0015 cost = 6.469527607\n",
      "Epoch: 0016 cost = 6.211510993\n",
      "Epoch: 0017 cost = 5.951969195\n",
      "Epoch: 0018 cost = 5.770207920\n",
      "Epoch: 0019 cost = 5.567523551\n",
      "Epoch: 0020 cost = 5.409057073\n",
      "Epoch: 0021 cost = 5.225529260\n",
      "Epoch: 0022 cost = 5.115692814\n",
      "Epoch: 0023 cost = 4.922357229\n",
      "Epoch: 0024 cost = 4.828075184\n",
      "Optimization Finished!\n",
      "Accuracy: 0.7503\n"
     ]
    }
   ],
   "source": [
    "Grapher(train_set, test_set, n_input, n_classes, [256, 256],\n",
    "        tf.train.GradientDescentOptimizer, activation=tf.nn.relu6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Epoch: 0001 cost = 161.324909730\n",
      "Epoch: 0002 cost = 42.605847155\n",
      "Epoch: 0003 cost = 27.092446155\n",
      "Epoch: 0004 cost = 18.928185773\n",
      "Epoch: 0005 cost = 13.638499924\n",
      "Epoch: 0006 cost = 10.507979187\n",
      "Epoch: 0007 cost = 7.581083359\n",
      "Epoch: 0008 cost = 5.892259366\n",
      "Epoch: 0009 cost = 4.339253664\n",
      "Epoch: 0010 cost = 3.284954584\n",
      "Epoch: 0011 cost = 2.483077058\n",
      "Epoch: 0012 cost = 1.824827947\n",
      "Epoch: 0013 cost = 1.411266974\n",
      "Epoch: 0014 cost = 1.027642392\n",
      "Epoch: 0015 cost = 0.890238776\n",
      "Epoch: 0016 cost = 0.588751286\n",
      "Epoch: 0017 cost = 0.632639819\n",
      "Optimization Finished!\n",
      "Accuracy: 0.9439\n"
     ]
    }
   ],
   "source": [
    "Grapher(train_set, test_set, n_input, n_classes, [256, 256],\n",
    "        tf.train.AdamOptimizer, activation=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Epoch: 0001 cost = 11656.389232289\n",
      "Epoch: 0002 cost = 2576.888508023\n",
      "Epoch: 0003 cost = 1521.778461540\n",
      "Epoch: 0004 cost = 921.037624425\n",
      "Epoch: 0005 cost = 618.953350626\n",
      "Epoch: 0006 cost = 418.070778136\n",
      "Epoch: 0007 cost = 276.746967639\n",
      "Epoch: 0008 cost = 210.410835565\n",
      "Epoch: 0009 cost = 143.992396416\n",
      "Epoch: 0010 cost = 114.645118584\n",
      "Epoch: 0011 cost = 95.811391312\n",
      "Epoch: 0012 cost = 82.438209940\n",
      "Epoch: 0013 cost = 77.402258797\n",
      "Epoch: 0014 cost = 62.501727035\n",
      "Epoch: 0015 cost = 64.486672124\n",
      "Epoch: 0016 cost = 60.762682703\n",
      "Epoch: 0017 cost = 61.763544250\n",
      "Epoch: 0018 cost = 60.295203682\n",
      "Epoch: 0019 cost = 51.085164257\n",
      "Epoch: 0020 cost = 42.559724841\n",
      "Epoch: 0021 cost = 37.925221639\n",
      "Epoch: 0022 cost = 47.848343113\n",
      "Epoch: 0023 cost = 35.715297865\n",
      "Epoch: 0024 cost = 45.053807521\n",
      "Epoch: 0025 cost = 47.460952774\n",
      "Epoch: 0026 cost = 33.219050219\n",
      "Epoch: 0027 cost = 32.914941593\n",
      "Epoch: 0028 cost = 41.677827588\n",
      "Epoch: 0029 cost = 36.751194100\n",
      "Epoch: 0030 cost = 29.356319802\n",
      "Epoch: 0031 cost = 28.858663609\n",
      "Epoch: 0032 cost = 24.721922650\n",
      "Epoch: 0033 cost = 27.466949566\n",
      "Epoch: 0034 cost = 29.849827991\n",
      "Epoch: 0035 cost = 28.391636676\n",
      "Epoch: 0036 cost = 22.770157818\n",
      "Epoch: 0037 cost = 34.033553432\n",
      "Epoch: 0038 cost = 30.902301864\n",
      "Epoch: 0039 cost = 19.959684304\n",
      "Epoch: 0040 cost = 29.066450746\n",
      "Epoch: 0041 cost = 26.389742685\n",
      "Epoch: 0042 cost = 20.651600650\n",
      "Epoch: 0043 cost = 29.785749426\n",
      "Epoch: 0044 cost = 25.016742654\n",
      "Epoch: 0045 cost = 24.677423803\n",
      "Epoch: 0046 cost = 16.631145926\n",
      "Epoch: 0047 cost = 19.781385162\n",
      "Epoch: 0048 cost = 26.717140596\n",
      "Epoch: 0049 cost = 23.381110400\n",
      "Epoch: 0050 cost = 19.519255685\n",
      "Epoch: 0051 cost = 22.595234653\n",
      "Epoch: 0052 cost = 19.166809474\n",
      "Epoch: 0053 cost = 17.868343121\n",
      "Epoch: 0054 cost = 18.476971827\n",
      "Epoch: 0055 cost = 16.736675277\n",
      "Epoch: 0056 cost = 20.745916252\n",
      "Epoch: 0057 cost = 21.316904590\n",
      "Epoch: 0058 cost = 15.815252217\n",
      "Epoch: 0059 cost = 12.919068700\n",
      "Epoch: 0060 cost = 20.306828632\n",
      "Epoch: 0061 cost = 25.066235227\n",
      "Epoch: 0062 cost = 11.353754015\n",
      "Epoch: 0063 cost = 14.738672668\n",
      "Epoch: 0064 cost = 18.097342825\n",
      "Epoch: 0065 cost = 18.146616187\n",
      "Optimization Finished!\n",
      "Accuracy: 0.9663\n"
     ]
    }
   ],
   "source": [
    "Grapher(train_set, test_set, n_input, n_classes, [512, 256, 256, 128],\n",
    "        tf.train.AdamOptimizer, activation=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Epoch: 0001 cost = 8.421146493\n",
      "Epoch: 0002 cost = 3.251908079\n",
      "Epoch: 0003 cost = 2.204635056\n",
      "Epoch: 0004 cost = 1.605988110\n",
      "Epoch: 0005 cost = 1.227234688\n",
      "Epoch: 0006 cost = 1.022173952\n",
      "Epoch: 0007 cost = 0.856822639\n",
      "Epoch: 0008 cost = 0.739583416\n",
      "Epoch: 0009 cost = 0.612919816\n",
      "Epoch: 0010 cost = 0.540722586\n",
      "Optimization Finished!\n",
      "Accuracy: 0.9149\n"
     ]
    }
   ],
   "source": [
    "Grapher(train_set, test_set, n_input, n_classes, [800, 800],\n",
    "        tf.train.AdamOptimizer, activation=tf.tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Epoch: 0001 cost = 14101.317995384\n",
      "Epoch: 0002 cost = 2902.710198364\n",
      "Epoch: 0003 cost = 1645.432493453\n",
      "Epoch: 0004 cost = 1078.996475599\n",
      "Epoch: 0005 cost = 707.609671101\n",
      "Epoch: 0006 cost = 486.602784084\n",
      "Epoch: 0007 cost = 338.621206574\n",
      "Epoch: 0008 cost = 232.569961710\n",
      "Epoch: 0009 cost = 165.607490565\n",
      "Epoch: 0010 cost = 97.782493746\n",
      "Epoch: 0011 cost = 76.551032037\n",
      "Epoch: 0012 cost = 51.486159956\n",
      "Epoch: 0013 cost = 38.167750156\n",
      "Epoch: 0014 cost = 35.862590961\n",
      "Epoch: 0015 cost = 26.271362687\n",
      "Epoch: 0016 cost = 20.911167633\n",
      "Epoch: 0017 cost = 17.416731048\n",
      "Epoch: 0018 cost = 17.935352062\n",
      "Epoch: 0019 cost = 10.805751886\n",
      "Epoch: 0020 cost = 10.230374276\n",
      "Epoch: 0021 cost = 8.220172869\n",
      "Epoch: 0022 cost = 7.297210685\n",
      "Epoch: 0023 cost = 5.800839519\n",
      "Epoch: 0024 cost = 5.076248872\n",
      "Epoch: 0025 cost = 4.806048712\n",
      "Epoch: 0026 cost = 3.774042987\n",
      "Epoch: 0027 cost = 3.612254013\n",
      "Epoch: 0028 cost = 3.669455304\n",
      "Optimization Finished!\n",
      "Accuracy: 0.9445\n"
     ]
    }
   ],
   "source": [
    "Grapher(train_set, test_set, n_input, n_classes, [512, 256, 256, 128],\n",
    "        tf.train.AdamOptimizer, activation=tf.nn.relu, has_exp_decay=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
